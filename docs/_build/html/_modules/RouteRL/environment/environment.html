<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>RouteRL.environment.environment &mdash; RouteRL 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            RouteRL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../modules.html">RouteRL</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">RouteRL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">RouteRL.environment.environment</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for RouteRL.environment.environment</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; PettingZoo environment for optimal route choice using SUMO simulator. &quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">gymnasium.spaces</span> <span class="kn">import</span> <span class="n">Discrete</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span> <span class="k">as</span> <span class="n">dc</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">threading</span>

<span class="kn">from</span> <span class="nn">..create_agents</span> <span class="kn">import</span> <span class="n">create_agent_objects</span>
<span class="kn">from</span> <span class="nn">.simulator</span> <span class="kn">import</span> <span class="n">SumoSimulator</span>
<span class="kn">from</span> <span class="nn">keychain</span> <span class="kn">import</span> <span class="n">Keychain</span> <span class="k">as</span> <span class="n">kc</span>
<span class="kn">from</span> <span class="nn">pettingzoo.utils.env</span> <span class="kn">import</span> <span class="n">AECEnv</span>
<span class="kn">from</span> <span class="nn">pettingzoo.utils</span> <span class="kn">import</span> <span class="n">agent_selector</span>
<span class="kn">from</span> <span class="nn">..utilities</span> <span class="kn">import</span> <span class="n">show_progress_bar</span>
<span class="kn">from</span> <span class="nn">.observations</span> <span class="kn">import</span> <span class="n">PreviousAgentStart</span>
<span class="kn">from</span> <span class="nn">.agent</span> <span class="kn">import</span> <span class="n">MachineAgent</span>
<span class="kn">from</span> <span class="nn">.plot_xml_files</span> <span class="kn">import</span> <span class="n">plot_all_xmls</span>


<span class="kn">from</span> <span class="nn">..services.recorder</span> <span class="kn">import</span> <span class="n">Recorder</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">)</span>


<div class="viewcode-block" id="TrafficEnvironment"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment">[docs]</a><span class="k">class</span> <span class="nc">TrafficEnvironment</span><span class="p">(</span><span class="n">AECEnv</span><span class="p">):</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;render_modes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;human&quot;</span><span class="p">],</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;TrafficEnvironment&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; A PettingZoo AECEnv interface for optimal route choice using SUMO simulator.</span>
<span class="sd">    This environment is utilized for the training of human agents (rational decision-makers) and machine agents (reinforcement learning agents).</span>
<span class="sd">    See https://sumo.dlr.de/docs/ for details on SUMO.</span>
<span class="sd">    See https://pettingzoo.farama.org/ for details on PettingZoo. </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">training_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">environment_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">simulation_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">agent_gen_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">agent_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">phases_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                 <span class="n">render_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>

<span class="sd">            training_params (dict): Training parameters.</span>
<span class="sd">            environment_params (dict): Environment parameters.</span>
<span class="sd">            simulation_params (dict): Simulation parameters.</span>
<span class="sd">            agent_gen_params (dict): Agent generation parameters.</span>
<span class="sd">            agent_params (dict): Agent parameters.</span>
<span class="sd">            phases_params (dict): Phases parameters.</span>
<span class="sd">            render_mode (str): The render mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">environment_params</span> <span class="o">=</span> <span class="n">environment_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_gen_params</span> <span class="o">=</span> <span class="n">agent_gen_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="o">=</span> <span class="n">training_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulation_params</span> <span class="o">=</span> <span class="n">simulation_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent_params</span> <span class="o">=</span> <span class="n">agent_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">render_mode</span> <span class="o">=</span> <span class="n">render_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phases_params</span> <span class="o">=</span> <span class="n">phases_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;travel_time&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ID</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_KIND</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">ACTION</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ORIGIN</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_DESTINATION</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_START_TIME</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_learning</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span> <span class="o">=</span> <span class="p">[]</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot; runner attributes &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">NUM_EPISODES</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phases</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">PHASES</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">PHASE_NAMES</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frequent_progressbar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">FREQUENT_PROGRESSBAR_UPDATE</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remember_every</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">REMEMBER_EVERY</span><span class="p">]</span>
<span class="w">        </span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; recorder attributes &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remember_episodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">ep</span> <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">remember_every</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">remember_every</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remember_episodes</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">ep</span><span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">ep</span> <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remember_episodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">remember_episodes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span> <span class="o">=</span> <span class="n">Recorder</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1">#############################</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">environment_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">ACTION_SPACE_SIZE</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span> <span class="o">=</span> <span class="n">SumoSimulator</span><span class="p">(</span><span class="n">simulation_params</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Simulator initiated!&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span> <span class="o">=</span> <span class="n">create_agent_objects</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agent_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_free_flow_times</span><span class="p">())</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">agent</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">kc</span><span class="o">.</span><span class="n">TYPE_MACHINE</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">agent</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">kc</span><span class="o">.</span><span class="n">TYPE_HUMAN</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;[AGENT TYPE INVALID] Unrecognized agent type: &#39;</span> <span class="o">+</span> <span class="n">agent</span><span class="o">.</span><span class="n">kind</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_machine_agents</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">human_learning</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">)</span><span class="si">}</span><span class="s2"> machine agents in the environment.&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">)</span><span class="si">}</span><span class="s2"> human agents in the environment.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">_initialize_machine_agents</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Initialize the machine agents. &quot;&quot;&quot;</span>
        
        <span class="c1">## Sort machine agents based on their start_time</span>
        <span class="n">sorted_machine_agents</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">agent</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">start_time</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">)</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">sorted_machine_agents</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">agent_name_mapping</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">))))</span>
        <span class="p">)</span>

        <span class="c1">## Initialize the observation object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_obj</span> <span class="o">=</span> <span class="n">PreviousAgentStart</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulation_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_spaces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_obj</span><span class="o">.</span><span class="n">observation_space</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_action_spaces</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">agent</span><span class="p">:</span> <span class="n">Discrete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">simulation_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">NUMBER_OF_PATHS</span><span class="p">])</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span>
        <span class="p">}</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Machine&#39;s observation space is: </span><span class="si">%s</span><span class="s2"> &quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_observation_spaces</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Machine&#39;s action space is: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_action_spaces</span><span class="p">)</span>

    
    <span class="c1">#############################</span>

    <span class="c1">##### Simulator control #####</span>

<div class="viewcode-block" id="TrafficEnvironment.start"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.start">[docs]</a>    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">start</span><span class="p">()</span></div>

<div class="viewcode-block" id="TrafficEnvironment.stop"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.stop">[docs]</a>    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span></div>


    <span class="c1">################################</span>

    <span class="c1">##### PettingZoo functions #####</span>

<div class="viewcode-block" id="TrafficEnvironment.reset"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resets the environment.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            seed (int, optional): Seed for random number generation. Defaults to None.</span>
<span class="sd">            options (dict, optional): Additional options for resetting the environment. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing the initial observations and information for the agents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">agents</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">terminations</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">truncations</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cumulative_rewards</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards_humans</span> <span class="o">=</span> <span class="p">{</span><span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span> <span class="o">=</span> <span class="n">agent_selector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">observations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_obj</span><span class="o">.</span><span class="n">reset_observation</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observations</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="p">{}</span>  <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">}</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">,</span> <span class="n">infos</span></div>


<div class="viewcode-block" id="TrafficEnvironment.step"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">machine_action</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Takes an action for the current agent (specified by agent_selection) and updates</span>
<span class="sd">        various parameters including rewards, cumulative rewards, terminations, truncations,</span>
<span class="sd">        infos, and agent_selection. Also updates any internal state used by observe() or render().</span>

<span class="sd">        Args:</span>
<span class="sd">            machine_action (int, optional): The action to be taken by the machine agent. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If there are machines in the system</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">terminations</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span><span class="p">]</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncations</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span><span class="p">]):</span>

                <span class="c1"># handles stepping an agent which is already dead</span>
                <span class="c1"># accepts a None action for the one agent, and moves the agent_selection to</span>
                <span class="c1"># the next dead agent,  or if there are no more dead agents, to the next live agent</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_was_dead_step</span><span class="p">(</span><span class="n">machine_action</span><span class="p">)</span>
                <span class="k">return</span>

            <span class="n">agent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span>

            <span class="c1"># The cumulative reward of the last agent must be 0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cumulative_rewards</span><span class="p">[</span><span class="n">agent</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">simulation_loop</span><span class="p">(</span><span class="n">machine_action</span><span class="p">,</span> <span class="n">agent</span><span class="p">)</span>

            <span class="c1"># Collect rewards if it is the last agent to act</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span><span class="o">.</span><span class="n">is_last</span><span class="p">():</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">day</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">+</span> <span class="mi">1</span>

                <span class="c1"># Calculate the rewards</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_assign_rewards</span><span class="p">()</span> 

                <span class="c1"># The episode ends when we complete episode_length days</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">truncations</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">agent</span><span class="p">:</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">EPISODE_LENGTH</span><span class="p">])</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents</span>
                <span class="p">}</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">terminations</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">agent</span><span class="p">:</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">EPISODE_LENGTH</span><span class="p">])</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents</span>
                <span class="p">}</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">agent</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents</span>
                <span class="p">}</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">observations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_obj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_reset_episode</span><span class="p">()</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># no rewards are allocated until all players give an action</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_clear_rewards</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

            <span class="c1"># Adds .rewards to ._cumulative_rewards</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_accumulate_rewards</span><span class="p">()</span>

        <span class="c1"># If there are only humans in the system</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">simulation_loop</span><span class="p">(</span><span class="n">machine_action</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">machine_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">day</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_assign_rewards</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_reset_episode</span><span class="p">()</span></div>


<div class="viewcode-block" id="TrafficEnvironment.close"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close the environment and stop the SUMO simulation.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_learning</span> <span class="o">=</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="TrafficEnvironment.observe"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.observe">[docs]</a>    <span class="k">def</span> <span class="nf">observe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the observations for a specific agent.</span>

<span class="sd">        Args:</span>
<span class="sd">            agent (str): The identifier for the agent whose observations are to be retrieved.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: The observations for the specified agent.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_obj</span><span class="o">.</span><span class="n">agent_observations</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="TrafficEnvironment.render"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.render">[docs]</a>    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span></div>


    <span class="c1">#########################</span>

    <span class="c1">### Mutation function ###</span>


<div class="viewcode-block" id="TrafficEnvironment.mutation"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.mutation">[docs]</a>    <span class="k">def</span> <span class="nf">mutation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform mutation by converting selected human agents into machine agents.</span>

<span class="sd">        This method identifies a subset of human agents that start after the 25th percentile of</span>
<span class="sd">        start times of other vehicles, removes a specified number of these agents, and replaces them with machine agents.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If there are insufficient human agents available for mutation.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Mutation is about to happen!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;There were </span><span class="si">%s</span><span class="s2"> human agents.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">))</span>

        <span class="c1"># Mutate to a human that starts after the 25% of the rest of the vehicles</span>
        <span class="n">start_times</span> <span class="o">=</span> <span class="p">[</span><span class="n">human</span><span class="o">.</span><span class="n">start_time</span> <span class="k">for</span> <span class="n">human</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">]</span>
        <span class="n">percentile_25</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">start_times</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>

        <span class="n">filtered_human_agents</span> <span class="o">=</span> <span class="p">[</span><span class="n">human</span> <span class="k">for</span> <span class="n">human</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span> <span class="k">if</span> <span class="n">human</span><span class="o">.</span><span class="n">start_time</span> <span class="o">&gt;</span> <span class="n">percentile_25</span><span class="p">]</span>

        <span class="n">number_of_machines_to_be_added</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent_gen_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">NEW_MACHINES_AFTER_MUTATION</span><span class="p">]</span>

        <span class="n">random_humans_deleted</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_human_agents</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">number_of_machines_to_be_added</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Insufficient human agents for mutation. Required: </span><span class="si">{</span><span class="n">number_of_machines_to_be_added</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Available: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">filtered_human_agents</span><span class="p">)</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Decrease the number of machines to be added after the mutation.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">number_of_machines_to_be_added</span><span class="p">):</span>
            <span class="n">random_human</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">filtered_human_agents</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">random_human</span><span class="p">)</span>
            <span class="n">filtered_human_agents</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">random_human</span><span class="p">)</span>

            <span class="n">random_humans_deleted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_human</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MachineAgent</span><span class="p">(</span><span class="n">random_human</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                                                    <span class="n">random_human</span><span class="o">.</span><span class="n">start_time</span><span class="p">,</span>
                                                    <span class="n">random_human</span><span class="o">.</span><span class="n">origin</span><span class="p">,</span> 
                                                    <span class="n">random_human</span><span class="o">.</span><span class="n">destination</span><span class="p">,</span> 
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">agent_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">MACHINE_PARAMETERS</span><span class="p">],</span> 
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">simulation_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">NUMBER_OF_PATHS</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">random_human</span><span class="o">.</span><span class="n">id</span><span class="p">))</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">machines</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">human_learning</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Now there are </span><span class="si">%s</span><span class="s2"> human agents.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_machine_agents</span><span class="p">()</span></div>


    <span class="c1">#########################</span>

    <span class="c1">##### Help functions #####</span>
    
<div class="viewcode-block" id="TrafficEnvironment.get_observation"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.get_observation">[docs]</a>    <span class="k">def</span> <span class="nf">get_observation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the current observation from the simulator.</span>

<span class="sd">        This method returns the current timestep of the simulation and the values of the episode actions.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing the current timestep and the episode actions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">timestep</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span><span class="o">.</span><span class="n">values</span><span class="p">()</span></div>

<div class="viewcode-block" id="TrafficEnvironment.help_step"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.help_step">[docs]</a>    <span class="k">def</span> <span class="nf">help_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; This function is responsible for supplying the simulator with the actions of vehicles</span>
<span class="sd">        that begin their journey at the current timestep. </span>
<span class="sd">        Simultaneously, it records the travel times of vehicles that finished their trip this timestep.&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">agent</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
            <span class="n">action_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ID</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_KIND</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">kind</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">ACTION</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span> \
                <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ORIGIN</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">origin</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_DESTINATION</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">destination</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_START_TIME</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">start_time</span><span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">add_vehice</span><span class="p">(</span><span class="n">action_dict</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span><span class="p">[</span><span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">action_dict</span>
        <span class="n">timestep</span><span class="p">,</span> <span class="n">arrivals</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">det_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  

        <span class="n">travel_times</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">veh_id</span> <span class="ow">in</span> <span class="n">arrivals</span><span class="p">:</span>
            <span class="n">agent_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">veh_id</span><span class="p">)</span>
            <span class="n">travel_times</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">kc</span><span class="o">.</span><span class="n">TRAVEL_TIME</span> <span class="p">:</span> <span class="p">(</span><span class="n">timestep</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span><span class="p">[</span><span class="n">agent_id</span><span class="p">][</span><span class="n">kc</span><span class="o">.</span><span class="n">AGENT_START_TIME</span><span class="p">])</span> <span class="o">/</span> <span class="mf">60.0</span><span class="p">}</span>
            <span class="n">travel_times</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span><span class="p">[</span><span class="n">agent_id</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">travel_times</span><span class="o">.</span><span class="n">values</span><span class="p">()</span></div>
    

    <span class="k">def</span> <span class="nf">_reset_episode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Reset the environment after one day implementation.&quot;&quot;&quot;</span>
        <span class="c1">#plot_all_xmls(self.day)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span> <span class="o">=</span> <span class="n">agent_selector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">possible_agents</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">agent_selection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

        <span class="n">phase_start_time</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">recording_task</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_record</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">day</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="p">,</span> <span class="n">phase_start_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span><span class="p">))</span>
        <span class="n">recording_task</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_actions</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    

    <span class="k">def</span> <span class="nf">_record</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ep_observations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">start_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">agents</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Record the episode data, including observations and rewards.</span>

<span class="sd">        This method logs the observations and rewards for the current episode and updates the progress of the simulation.</span>

<span class="sd">        Args:</span>
<span class="sd">            episode (int): The current episode number.</span>
<span class="sd">            ep_observations (dict): Observations recorded during the episode.</span>
<span class="sd">            start_time (float): The start time of the episode.</span>
<span class="sd">            agents (list): List of agent objects to record rewards for.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dc_episode</span><span class="p">,</span> <span class="n">dc_ep_observations</span><span class="p">,</span> <span class="n">dc_start_time</span><span class="p">,</span> <span class="n">dc_agents</span> <span class="o">=</span> <span class="n">dc</span><span class="p">(</span><span class="n">episode</span><span class="p">),</span> <span class="n">dc</span><span class="p">(</span><span class="n">ep_observations</span><span class="p">),</span> <span class="n">dc</span><span class="p">(</span><span class="n">start_time</span><span class="p">),</span> <span class="n">dc</span><span class="p">(</span><span class="n">agents</span><span class="p">)</span>

        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[{</span><span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ID</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">kc</span><span class="o">.</span><span class="n">REWARD</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">last_reward</span><span class="p">}</span> <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">dc_agents</span><span class="p">]</span>
        <span class="n">cost_tables</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ID</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="n">kc</span><span class="o">.</span><span class="n">COST_TABLE</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;cost&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="n">dc_agents</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">dc_episode</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">remember_episodes</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">dc_episode</span><span class="p">,</span> <span class="n">dc_ep_observations</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">cost_tables</span><span class="p">)</span><span class="c1">#, self.det_dict)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequent_progressbar</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">phase_names</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">curr_progress</span> <span class="o">=</span> <span class="n">dc_episode</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">))</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_episodes</span><span class="o">+</span><span class="mi">1</span>
        <span class="n">target</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">phases</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_phase</span><span class="p">]</span>
        <span class="c1">#show_progress_bar(msg, dc_start_time, curr_progress, target)</span>


    <span class="k">def</span> <span class="nf">_assign_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; This function assigns rewards to the agents. &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">agent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="p">)</span>

            <span class="c1"># Add the reward in the travel_times_list</span>
            <span class="k">for</span> <span class="n">agent_entry</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">agent</span><span class="o">.</span><span class="n">id</span> <span class="o">==</span> <span class="n">agent_entry</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">AGENT_ID</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">agent_entry</span><span class="p">)</span>
                    <span class="n">agent_entry</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">REWARD</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_entry</span><span class="p">)</span>

            <span class="c1"># Save machine&#39;s rewards based on PettingZoo standards</span>
            <span class="k">if</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;AV&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">id</span><span class="p">)]</span> <span class="o">=</span> <span class="n">reward</span>

            <span class="c1"># Human learning</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_learning</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">last_action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="p">)</span>

    <span class="c1">###########################</span>

    <span class="c1">##### Simulation loop #####</span>

<div class="viewcode-block" id="TrafficEnvironment.simulation_loop"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.simulation_loop">[docs]</a>    <span class="k">def</span> <span class="nf">simulation_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">machine_action</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">machine_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; This function contains the integration of the agent&#39;s actions to SUMO. </span>
<span class="sd">        Description:</span>
<span class="sd">            We iterate through all the timesteps of the simulation.</span>
<span class="sd">            For each timestep there are None, one or more than one agents (humans, machines) that start. </span>
<span class="sd">            If more than one machine agents have the same start time, we break from this function because we need to take the agent&#39;s action from the STEP function.</span>
<span class="sd">        Data structures:</span>
<span class="sd">            self.machine_same_start_time (list): contains the machine agents that their start time is equal to the simulator timestep</span>
<span class="sd">                and haven&#39;t acted yet.</span>
<span class="sd">            self.actions_timestep (list): includes the agents (machines/humans) that have acted in this timestep and</span>
<span class="sd">                their action will be send in the simulator</span>
<span class="sd">            agent_action (bool): break if the agent acting is not the last one (because the next agent should STEP first)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">agent_action</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">timestep</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulation_params</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">SIMULATION_TIMESTEPS</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_agents</span><span class="p">):</span>

            <span class="c1"># If there are more than one machines with the same start time</span>
            <span class="c1"># the humans should act once</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">human</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">human_agents</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">human</span><span class="o">.</span><span class="n">start_time</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">timestep</span><span class="p">:</span>
                        <span class="n">action</span> <span class="o">=</span> <span class="n">human</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">human</span><span class="o">.</span><span class="n">last_action</span> <span class="o">=</span> <span class="n">action</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">human</span><span class="p">,</span> <span class="n">action</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">machine</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">machine_agents</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">machine</span><span class="o">.</span><span class="n">start_time</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">timestep</span><span class="p">:</span>

                    <span class="c1"># In case there are machine agents that have the same start time but it&#39;s not their turn</span>
                    <span class="k">if</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">machine</span><span class="o">.</span><span class="n">id</span><span class="p">)</span> <span class="o">!=</span> <span class="n">machine_id</span><span class="p">):</span>

                        <span class="c1"># If some machines have the same start time and they haven&#39;t acted yet</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">machine</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">machine</span> <span class="o">==</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">machine</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Machine acting</span>
                        <span class="n">machine</span><span class="o">.</span><span class="n">last_action</span> <span class="o">=</span> <span class="n">machine_action</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">machine</span><span class="p">,</span> <span class="n">machine_action</span><span class="p">))</span>  

                        <span class="c1"># The machine acted should be deleted from the self.machine_same_start_time list</span>
                        <span class="k">if</span> <span class="n">machine</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">machine</span><span class="p">)</span>

                        <span class="c1"># If the machine isn&#39;t the last agent to act then we need to step again for the next agent</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent_selector</span><span class="o">.</span><span class="n">is_last</span><span class="p">():</span>
                            <span class="n">agent_action</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># If all machines that have start time as the simulator timestep acted</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span><span class="p">:</span> 
                <span class="n">travel_times</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">help_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">agent_dict</span> <span class="ow">in</span> <span class="n">travel_times</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">travel_times_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agent_dict</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">actions_timestep</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">machine_same_start_time</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># If the machine agent that had turn acted</span>
            <span class="k">if</span> <span class="n">agent_action</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">agent_action</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">break</span></div>

    
    <span class="c1">###########################</span>

    <span class="c1">##### Free flow times #####</span>

<div class="viewcode-block" id="TrafficEnvironment.get_free_flow_times"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.get_free_flow_times">[docs]</a>    <span class="k">def</span> <span class="nf">get_free_flow_times</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve free flow times for all origin-destination pairs from the simulator paths data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary where keys are tuples of origin and destination, and values are lists of free flow times.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">paths_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">simulator</span><span class="o">.</span><span class="n">paths_csv_path</span><span class="p">)</span>
        <span class="n">origins</span> <span class="o">=</span> <span class="n">paths_df</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">ORIGIN</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
        <span class="n">destinations</span> <span class="o">=</span> <span class="n">paths_df</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">DESTINATION</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
        <span class="n">ff_dict</span> <span class="o">=</span> <span class="p">{(</span><span class="n">o</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span> <span class="nb">list</span><span class="p">()</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">origins</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">destinations</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">paths_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">ff_dict</span><span class="p">[(</span><span class="n">row</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">ORIGIN</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">DESTINATION</span><span class="p">])]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">kc</span><span class="o">.</span><span class="n">FREE_FLOW_TIME</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">ff_dict</span></div>
    
   
    <span class="c1">############################</span>
    <span class="c1">### PettingZoo functions ###</span>


<div class="viewcode-block" id="TrafficEnvironment.observation_space"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.observation_space">[docs]</a>    <span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">observation_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_observation_spaces</span><span class="p">[</span><span class="n">agent</span><span class="p">]</span></div>


<div class="viewcode-block" id="TrafficEnvironment.action_space"><a class="viewcode-back" href="../../../RouteRL.environment.html#RouteRL.environment.environment.TrafficEnvironment.action_space">[docs]</a>    <span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">action_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_action_spaces</span><span class="p">[</span><span class="n">agent</span><span class="p">]</span></div></div>
    
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Anastasia Psarou, Ahmet Onur Akman.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>