{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to our PettingZoo Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have created a framework that integrates reinforcement learning (RL) with a microscopic traffic simulation tool to explore the potential of RL in optimizing urban route choice.\n",
    "\n",
    "> We use [SUMO](https://sumo.dlr.de/docs/index.html), an open-source, microscopic and continuous traffic simulation.\n",
    "\n",
    "## Related work\n",
    "\n",
    "> Some methods have utilized RL for optimal route choice (Thomasini et al. [2023](https://alaworkshop2023.github.io/papers/ALA2023_paper_69.pdf/)). These approaches\n",
    "are typically based on macroscopic traffic simulations, which model relationships among traffic\n",
    "flow characteristics such as density, flow, and mean speed of a traffic stream. In contrast, our\n",
    "problem employs a microscopic model, which focuses on interactions between individual vehicles.\n",
    "\n",
    "> Additionally, a method proposed by (Tavares and Bazzan [2012](https://www.researchgate.net/publication/235219033_Reinforcement_learning_for_route_choice_in_an_abstract_traffic_scenario)) addresses optimal route choice at the microscopic level, where rewards are generated through a predefined function. In contrast, in our approach, rewards are provided dynamically by a continuous traffic simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "from routerl.environment.environment import TrafficEnvironment\n",
    "from routerl.services import plotter\n",
    "from routerl.keychain import Keychain as kc\n",
    "\n",
    "from routerl.create_agents import create_agent_objects\n",
    "from routerl.utilities import check_device\n",
    "from routerl.utilities import get_params\n",
    "from routerl.utilities import set_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "check_device()\n",
    "set_seeds()\n",
    "params = get_params(\"params_main.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this example, the environment initially contains only human agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"learning_type\" : 'markow',\n",
    "        \"gamma_c\" : 0.2,\n",
    "        \"gamma_u\" : 0.2,\n",
    "        \"remember\" : 5,\n",
    "        \"greedy\" : 0.3,\n",
    "        \"noise_alpha\" : 0,\n",
    "        \"noise_taste\" : 0.8,\n",
    "        \"noise_random\" : 0.2,\n",
    "        \"network\":'test'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIRMED] Environment variable exists: SUMO_HOME\n",
      "[SUCCESS] Added module directory: /opt/homebrew/opt/sumo/share/sumo/tools\n",
      "here\n",
      "   origins  destinations                                               path  \\\n",
      "0        0             0  441496282#0,441496282#1,441496282#2,441496282#...   \n",
      "1        0             0  441496282#0,441496282#1,441496282#2,441496282#...   \n",
      "\n",
      "   free_flow_time  \n",
      "0               0  \n",
      "1               0  \n"
     ]
    }
   ],
   "source": [
    "env = TrafficEnvironment(params[kc.RUNNER], params[kc.ENVIRONMENT], params[kc.SIMULATOR], params[kc.AGENT_GEN], params[kc.AGENTS], params[kc.PLOTTER],**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total agents is:  20 \n",
      "\n",
      "Agents are:  [<agent.HumanAgent object at 0x103215fa0>, <agent.HumanAgent object at 0x1519f0dc0>, <agent.HumanAgent object at 0x103227ac0>, <agent.HumanAgent object at 0x103227910>, <agent.HumanAgent object at 0x103288430>, <agent.HumanAgent object at 0x1032276a0>, <agent.HumanAgent object at 0x10315ce50>, <agent.HumanAgent object at 0x1032887c0>, <agent.HumanAgent object at 0x10315cd60>, <agent.HumanAgent object at 0x103227c10>, <agent.HumanAgent object at 0x1519f0f40>, <agent.HumanAgent object at 0x1032883d0>, <agent.HumanAgent object at 0x103227cd0>, <agent.HumanAgent object at 0x103288760>, <agent.HumanAgent object at 0x28adb0430>, <agent.HumanAgent object at 0x28adb0550>, <agent.HumanAgent object at 0x28adb0d60>, <agent.HumanAgent object at 0x28adb0dc0>, <agent.HumanAgent object at 0x28adb0df0>, <agent.HumanAgent object at 0x28adb0e20>] \n",
      "\n",
      "Number of human agents is:  20 \n",
      "\n",
      "Number of machine agents (autonomous vehicles) is:  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total agents is: \", len(env.all_agents), \"\\n\")\n",
    "print(\"Agents are: \", env.all_agents, \"\\n\")\n",
    "print(\"Number of human agents is: \", len(env.human_agents), \"\\n\")\n",
    "print(\"Number of machine agents (autonomous vehicles) is: \", len(env.machine_agents), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reset the environment and the connection with SUMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "RoutingZoo = str(Path.home() / \"Documents/Simulator_human_behaviour\")\n",
    "sys.path.append(RoutingZoo)\n",
    "import utilities_RZ as URZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Could not set locale to 'C'.\n",
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n",
      "Warning: Could not set locale to 'C'.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'demand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[1;32m      7\u001b[0m     env\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m----> 9\u001b[0m     URZ_help \u001b[38;5;241m=\u001b[39m \u001b[43mURZ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUtilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRoutingZoo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     URZ_help\u001b[38;5;241m.\u001b[39mdata()\n\u001b[1;32m     13\u001b[0m     URZ_help\u001b[38;5;241m.\u001b[39mReplace_data()\n",
      "File \u001b[0;32m~/Documents/Simulator_human_behaviour/utilities_RZ.py:12\u001b[0m, in \u001b[0;36mUtilities.__init__\u001b[0;34m(self, env, RoutingZoo, episode, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRoutingZoo \u001b[38;5;241m=\u001b[39m RoutingZoo\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode \u001b[38;5;241m=\u001b[39m episode\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_folder()\n",
      "File \u001b[0;32m~/Documents/Simulator_human_behaviour/utilities_RZ.py:67\u001b[0m, in \u001b[0;36mUtilities.name\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m network \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     66\u001b[0m model \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 67\u001b[0m demand \u001b[38;5;241m=\u001b[39m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdemand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m Bounded \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma_c\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     69\u001b[0m Greedy \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'demand'"
     ]
    }
   ],
   "source": [
    "num_episodes =  1\n",
    "\n",
    "env.start()\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    env.step()\n",
    "\n",
    "    URZ_help = URZ.Utilities(env,RoutingZoo,episode,**kwargs)\n",
    "\n",
    "    URZ_help.data()\n",
    "\n",
    "    URZ_help.Replace_data()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_episodes =  1\n",
    "\n",
    "env.start()\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    env.step()\n",
    "\n",
    "    id = []\n",
    "    Utilities = []\n",
    "    Noises = []\n",
    "\n",
    "    for a in range(len(env.human_agents)):\n",
    "\n",
    "        id.append(env.human_agents[a].id)\n",
    "        Utilities.append(env.human_agents[a].stored_utilities)\n",
    "        Noises.append(env.human_agents[a].stored_noises)\n",
    "\n",
    "    data = pd.DataFrame([id,Utilities,Noises]).T\n",
    "    data = data.rename(columns={0:'id',1:'utilities',2:'noises'})\n",
    "    data.to_csv(f'{RoutingZoo}/training_records/agents/ep_{episode+1}.csv',index=False)\n",
    "    import shutil\n",
    "\n",
    "    os.rename(f'/Users/zoltanvarga/Documents/RouteRL/tutorials/PettingZooEnv/training_records/episodes/ep{episode+1}.csv',f'/Users/zoltanvarga/Documents/RouteRL/tutorials/PettingZooEnv/training_records/episodes/ep_ep{episode+1}.csv')\n",
    "    source = f'/Users/zoltanvarga/Documents/RouteRL/tutorials/PettingZooEnv/training_records/episodes/ep_ep{episode+1}.csv'\n",
    "    destination = f'{RoutingZoo}/training_records/episodes/ep_ep{episode+1}.csv'\n",
    "\n",
    "    shutil.copy2(source, destination)\n",
    "\n",
    "env.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the path to FolderB\n",
    "simulator_path = str(Path.home() / \"Documents/Simulator_human_behaviour\")\n",
    "sys.path.append(simulator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_analysis as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = da.Table_record_creator(1,URZ_help.model,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run was succesful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>model</th>\n",
       "      <th>demand</th>\n",
       "      <th>Bounded</th>\n",
       "      <th>Greedy</th>\n",
       "      <th>link_value</th>\n",
       "      <th>link_std</th>\n",
       "      <th>TT_value</th>\n",
       "      <th>TT_std</th>\n",
       "      <th>entropy_value</th>\n",
       "      <th>entropy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>markow</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network   model demand Bounded Greedy  link_value  link_std  TT_value  \\\n",
       "0    test  markow     20     0.2    0.3         0.0       0.0      13.0   \n",
       "\n",
       "   TT_std  entropy_value  entropy_std  \n",
       "0     0.0            0.0          0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program.table_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mutation: a portion of human agents are converted into machine agents (autonomous vehicles). You can adjust the number of agents to be mutated in the <code style=\"color:white\">/params_main.json</code> file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.mutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total agents is:  20 \n",
      "\n",
      "Agents are:  [<agent.HumanAgent object at 0x106e629a0>, <agent.HumanAgent object at 0x106e75460>, <agent.HumanAgent object at 0x15e4af670>, <agent.HumanAgent object at 0x106e62e20>, <agent.HumanAgent object at 0x15efcf2b0>, <agent.HumanAgent object at 0x15e4affa0>, <agent.HumanAgent object at 0x106ebc520>, <agent.HumanAgent object at 0x1076087f0>, <agent.HumanAgent object at 0x107608850>, <agent.HumanAgent object at 0x106ee6760>, <agent.HumanAgent object at 0x106e757f0>, <agent.HumanAgent object at 0x107881f40>, <agent.HumanAgent object at 0x107881f70>, <agent.HumanAgent object at 0x106ee6370>, <agent.HumanAgent object at 0x106ebcca0>, <agent.HumanAgent object at 0x106ee63d0>, <agent.HumanAgent object at 0x1078812e0>, <agent.HumanAgent object at 0x15e4af730>, <agent.HumanAgent object at 0x15e4afe20>, <agent.HumanAgent object at 0x106ebc220>] \n",
      "\n",
      "Number of human agents is:  20 \n",
      "\n",
      "Number of machine agents (autonomous vehicles) is:  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total agents is: \", len(env.all_agents), \"\\n\")\n",
    "print(\"Agents are: \", env.all_agents, \"\\n\")\n",
    "print(\"Number of human agents is: \", len(env.human_agents), \"\\n\")\n",
    "print(\"Number of machine agents (autonomous vehicles) is: \", len(env.machine_agents), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Machine 7,\n",
       " Machine 17,\n",
       " Machine 12,\n",
       " Machine 11,\n",
       " Machine 10,\n",
       " Machine 8,\n",
       " Machine 13,\n",
       " Machine 16,\n",
       " Machine 5,\n",
       " Machine 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.machine_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting episode 1\n",
      "Agent 5 takes action: 0\n",
      "Agent 5 has stepped, environment updated.\n",
      "\n",
      "Agent 6 takes action: 1\n",
      "Agent 6 has stepped, environment updated.\n",
      "\n",
      "Agent 7 takes action: 1\n",
      "Agent 7 has stepped, environment updated.\n",
      "\n",
      "Agent 8 takes action: 1\n",
      "Agent 8 has stepped, environment updated.\n",
      "\n",
      "Agent 10 takes action: 0\n",
      "Agent 10 has stepped, environment updated.\n",
      "\n",
      "Agent 11 takes action: 1\n",
      "Agent 11 has stepped, environment updated.\n",
      "\n",
      "Agent 12 takes action: 0\n",
      "Agent 12 has stepped, environment updated.\n",
      "\n",
      "Agent 13 takes action: 1\n",
      "Agent 13 has stepped, environment updated.\n",
      "\n",
      "Agent 16 takes action: 1\n",
      "Agent 16 has stepped, environment updated.\n",
      "\n",
      "Agent 17 takes action: 0\n",
      "Agent 17 has stepped, environment updated.\n",
      "\n",
      "Agent 5 takes action: None\n",
      "Agent 5 has stepped, environment updated.\n",
      "\n",
      "Agent 6 takes action: None\n",
      "Agent 6 has stepped, environment updated.\n",
      "\n",
      "Agent 7 takes action: None\n",
      "Agent 7 has stepped, environment updated.\n",
      "\n",
      "Agent 8 takes action: None\n",
      "Agent 8 has stepped, environment updated.\n",
      "\n",
      "Agent 10 takes action: None\n",
      "Agent 10 has stepped, environment updated.\n",
      "\n",
      "Agent 11 takes action: None\n",
      "Agent 11 has stepped, environment updated.\n",
      "\n",
      "Agent 12 takes action: None\n",
      "Agent 12 has stepped, environment updated.\n",
      "\n",
      "Agent 13 takes action: None\n",
      "Agent 13 has stepped, environment updated.\n",
      "\n",
      "Agent 16 takes action: None\n",
      "Agent 16 has stepped, environment updated.\n",
      "\n",
      "Agent 17 takes action: None\n",
      "Agent 17 has stepped, environment updated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "\n",
    "for episode in range(episodes):\n",
    "    print(f\"\\nStarting episode {episode + 1}\")\n",
    "    env.reset()\n",
    "    \n",
    "    for agent in env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "        if termination or truncation:\n",
    "            action = None\n",
    "        else:\n",
    "            # Policy action or random sampling\n",
    "            action = env.action_space(agent).sample()\n",
    "        print(f\"Agent {agent} takes action: {action}\")\n",
    "        \n",
    "        env.step(action)\n",
    "        print(f\"Agent {agent} has stepped, environment updated.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:white\">agent_iter(max_iter=2**63)</code> returns an iterator that yields the current agent of the environment. It terminates when all agents in the environment are done or when max_iter (steps have been executed).\n",
    "\n",
    "<code style=\"color:white\">last(observe=True)</code> returns observation, reward, done, and info for the agent currently able to act. The returned reward is the cumulative reward that the agent has received since it last acted. If observe is set to False, the observation will not be computed, and None will be returned in its place. Note that a single agent being done does not imply the environment is done.\n",
    "\n",
    "<code style=\"color:white\">reset()</code> resets the environment and sets it up for use when called the first time. This method must be called before any other method.\n",
    "\n",
    "<code style=\"color:white\">step(action)</code> takes and executes the action of the agent in the environment, automatically switches control to the next agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Close SUMO connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FatalTraCIError",
     "evalue": "Connection closed by SUMO.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFatalTraCIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anastasia\\Documents\\RouteRL\\RouteRL\\environment\\environment.py:158\u001b[0m, in \u001b[0;36mTrafficEnvironment.stop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anastasia\\Documents\\RouteRL\\RouteRL\\environment\\simulator.py:88\u001b[0m, in \u001b[0;36mSumoSimulator.stop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    Stops and closes the SUMO simulation.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msumo_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py:396\u001b[0m, in \u001b[0;36mConnection.close\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremoveStepListener(listenerID)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendCmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCMD_CLOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py:231\u001b[0m, in \u001b[0;36mConnection._sendCmd\u001b[1;34m(self, cmdID, varID, objID, format, *values)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(objID)) \u001b[38;5;241m+\u001b[39m objID\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m packed\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendExact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py:137\u001b[0m, in \u001b[0;36mConnection._sendExact\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FatalTraCIError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection closed by SUMO.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m command \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue:\n\u001b[0;32m    139\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!BBB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFatalTraCIError\u001b[0m: Connection closed by SUMO."
     ]
    }
   ],
   "source": [
    "env.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RouteRL.services import plotter\n",
    "plotter(params[kc.PLOTTER])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
