{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Coexistence-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ERC Starting Grant on COeXISTENCE between humans and machines in urban mobility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img_mileston1.png\" alt=\"Milestone 1 Image\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: My Notebook Title\n",
    "## Name: Your Name\n",
    "### Date: March 4, 2024\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "> This notebook serves as an illustrative example showcasing the experiments conducted for Milestone 1. \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of Experiment Execution\n",
    "\n",
    "> The duration of this experiment was measured to be...\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Objective\n",
    "\n",
    "> The objective of this experiment is to see....\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outcome\n",
    "\n",
    "> Describe what we anticipate observing.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Summary\n",
    "\n",
    "### Network Architecture\n",
    "- Csomor network\n",
    "\n",
    "\n",
    "### Agents\n",
    "| **Type**          | Altruistic          |\n",
    "|-------------------|---------------------|\n",
    "| **Number**        | 600                 |\n",
    "| **New agents are created every** | 6 steps |\n",
    "\n",
    "\n",
    "### Origin and Destination Details\n",
    "| **Origin Count**      | 2                            |\n",
    "|-----------------------|------------------------------|\n",
    "| **Destination Count** | 2                            |\n",
    "| **Origin Pairing**    | 279952229#0, 115604053       |\n",
    "| **Destination Pairing**| -335062734#1, 23130852#3     |\n",
    "\n",
    "\n",
    "\n",
    "### Reinforcement Learning Algorithm\n",
    "- **Algorithm:** Proximal Policy Optimization (PPO)\n",
    "  - **PPO Hyperparameters:**\n",
    "    | Gamma | Learning Rate | Timesteps |\n",
    "    |-------|---------------|-----------|\n",
    "    | 0.9   | 1e-3          | 1000      |\n",
    "\n",
    "    \n",
    "\n",
    "### Hardware Utilized for Experiment Execution\n",
    "| **Type of Machine** | Personal computer (or server) |\n",
    "|----------------------|-------------------------------|\n",
    "| **CPU**              | 12th Gen Intel(R) Core(TM) i7-1255U |\n",
    "|                      | Cores: 10                   |\n",
    "|                      | Sockets: 1                  |\n",
    "|                      | Base Speed: 1.70 GHz        |\n",
    "| **Memory**           | 16GB                          |\n",
    "| **Disc (SSD)**       | 477 GB                        |\n",
    "| **Operating System** | Windows 11                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import TrafficEnvironment\n",
    "from keychain import Keychain as kc\n",
    "import os\n",
    "from Sumo_controller import Sumo\n",
    "\n",
    "from utilities import confirm_env_variable\n",
    "from utilities import get_params\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm_env_variable(kc.SUMO_HOME, append=\"tools\")\n",
    "params = get_params(kc.PARAMS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sumo_sim=Sumo(params)\n",
    "Sumo_sim.Sumo_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Parameters in the Parameters Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_paths = 3\n",
    "origins = [\"279952229#0\", \"115604053\"]\n",
    "destinations = [\"-335062734#1\", \"23130852#3\"]\n",
    "num_agents = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the number of paths used in this experiment\n",
    "simulator_params = params[kc.SIMULATION_PARAMETERS]\n",
    "\n",
    "for key, value in simulator_params.items():\n",
    "    if key == \"number_of_paths\":\n",
    "        simulator_params[key] = number_of_paths\n",
    "    if key =='origins':\n",
    "        simulator_params[key] = origins\n",
    "    if key == 'destinations':\n",
    "        simulator_params[key] = destinations\n",
    "\n",
    "params[kc.SIMULATION_PARAMETERS] = simulator_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_generation_params = params[kc.AGENTS_GENERATION_PARAMETERS]\n",
    "\n",
    "for key, value in agent_generation_params.items():\n",
    "    if key == \"num_agents\":\n",
    "        agent_generation_params[key] = num_agents\n",
    "\n",
    "params[kc.AGENTS_GENERATION_PARAMETERS] = agent_generation_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TrafficEnvironment(params[kc.ENVIRONMENT_PARAMETERS], params[kc.SIMULATION_PARAMETERS], params[kc.AGENTS_GENERATION_PARAMETERS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    ">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "> What were our observations? Did they support the hypothesis or prove the intended point?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "```{bibliography}:style: unsrt\n",
    "\n",
    "- Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). Proximal Policy Optimization Algorithms. arXiv preprint arXiv:1707.06347."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
