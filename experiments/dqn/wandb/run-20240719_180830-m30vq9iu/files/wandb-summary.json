{"train/episode_reward_2": -3.2400002479553223, "trainer/step": 800, "_timestamp": 1721405834.66519, "_runtime": 524.254998922348, "_step": 21599, "train/episode_reward_6": -3.950000286102295, "train/episode_reward_3": -2.37333345413208, "train/episode_reward_4": -1.753333330154419, "train/q_values_2": -164.0174072265625, "train/q_loss_2": 1.6419490575790405, "train/epsilon_2": 0.2800162732601166, "train/sampling_time": 8.989133834838867, "train/training_time": 3.58655047416687, "train/q_values_6": -169.46661376953125, "train/q_loss_6": 0.3654675781726837, "train/epsilon_6": 0.2800162732601166, "train/q_values_3": -150.478515625, "train/q_loss_3": 3.0753915309906006, "train/epsilon_3": 0.2800162732601166, "train/q_values_4": -10.070073699951172, "train/q_loss_4": 0.9381430745124817, "train/epsilon_4": 0.2800162732601166}